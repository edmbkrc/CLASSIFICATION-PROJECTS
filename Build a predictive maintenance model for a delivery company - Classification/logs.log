2024-03-20 13:44:05,788:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-20 13:44:05,788:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-20 13:44:05,788:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-20 13:44:05,788:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-20 13:58:24,762:INFO:PyCaret ClassificationExperiment
2024-03-20 13:58:24,762:INFO:Logging name: clf-default-name
2024-03-20 13:58:24,762:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-03-20 13:58:24,762:INFO:version 3.3.0
2024-03-20 13:58:24,762:INFO:Initializing setup()
2024-03-20 13:58:24,762:INFO:self.USI: 170a
2024-03-20 13:58:24,762:INFO:self._variable_keys: {'X_test', 'html_param', 'gpu_param', 'log_plots_param', 'is_multiclass', 'seed', 'fold_generator', '_ml_usecase', 'exp_id', 'idx', 'exp_name_log', 'n_jobs_param', 'fold_shuffle_param', '_available_plots', 'USI', 'target_param', 'logging_param', 'X', 'y_test', 'fix_imbalance', 'X_train', 'gpu_n_jobs_param', 'pipeline', 'y', 'fold_groups_param', 'y_train', 'data', 'memory'}
2024-03-20 13:58:24,762:INFO:Checking environment
2024-03-20 13:58:24,762:INFO:python_version: 3.11.5
2024-03-20 13:58:24,762:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-03-20 13:58:24,762:INFO:machine: AMD64
2024-03-20 13:58:24,762:INFO:platform: Windows-10-10.0.22621-SP0
2024-03-20 13:58:24,762:INFO:Memory: svmem(total=34128322560, available=19463835648, percent=43.0, used=14664486912, free=19463835648)
2024-03-20 13:58:24,762:INFO:Physical Core: 6
2024-03-20 13:58:24,762:INFO:Logical Core: 12
2024-03-20 13:58:24,763:INFO:Checking libraries
2024-03-20 13:58:24,763:INFO:System:
2024-03-20 13:58:24,763:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-03-20 13:58:24,763:INFO:executable: C:\Users\admcn\anaconda3\python.exe
2024-03-20 13:58:24,763:INFO:   machine: Windows-10-10.0.22621-SP0
2024-03-20 13:58:24,763:INFO:PyCaret required dependencies:
2024-03-20 13:58:25,520:INFO:                 pip: 23.2.1
2024-03-20 13:58:25,520:INFO:          setuptools: 68.0.0
2024-03-20 13:58:25,520:INFO:             pycaret: 3.3.0
2024-03-20 13:58:25,520:INFO:             IPython: 8.15.0
2024-03-20 13:58:25,520:INFO:          ipywidgets: 8.0.4
2024-03-20 13:58:25,520:INFO:                tqdm: 4.65.0
2024-03-20 13:58:25,520:INFO:               numpy: 1.24.3
2024-03-20 13:58:25,520:INFO:              pandas: 2.1.4
2024-03-20 13:58:25,520:INFO:              jinja2: 3.1.2
2024-03-20 13:58:25,520:INFO:               scipy: 1.11.1
2024-03-20 13:58:25,520:INFO:              joblib: 1.2.0
2024-03-20 13:58:25,520:INFO:             sklearn: 1.4.1.post1
2024-03-20 13:58:25,520:INFO:                pyod: 1.1.3
2024-03-20 13:58:25,520:INFO:            imblearn: 0.12.0
2024-03-20 13:58:25,520:INFO:   category_encoders: 2.6.3
2024-03-20 13:58:25,520:INFO:            lightgbm: 4.3.0
2024-03-20 13:58:25,520:INFO:               numba: 0.57.1
2024-03-20 13:58:25,520:INFO:            requests: 2.31.0
2024-03-20 13:58:25,520:INFO:          matplotlib: 3.7.2
2024-03-20 13:58:25,520:INFO:          scikitplot: 0.3.7
2024-03-20 13:58:25,520:INFO:         yellowbrick: 1.5
2024-03-20 13:58:25,520:INFO:              plotly: 5.20.0
2024-03-20 13:58:25,520:INFO:    plotly-resampler: Not installed
2024-03-20 13:58:25,520:INFO:             kaleido: 0.2.1
2024-03-20 13:58:25,520:INFO:           schemdraw: 0.15
2024-03-20 13:58:25,520:INFO:         statsmodels: 0.14.0
2024-03-20 13:58:25,520:INFO:              sktime: 0.27.0
2024-03-20 13:58:25,520:INFO:               tbats: 1.1.3
2024-03-20 13:58:25,520:INFO:            pmdarima: 2.0.4
2024-03-20 13:58:25,520:INFO:              psutil: 5.9.0
2024-03-20 13:58:25,520:INFO:          markupsafe: 2.1.1
2024-03-20 13:58:25,520:INFO:             pickle5: Not installed
2024-03-20 13:58:25,520:INFO:         cloudpickle: 2.2.1
2024-03-20 13:58:25,520:INFO:         deprecation: 2.1.0
2024-03-20 13:58:25,520:INFO:              xxhash: 2.0.2
2024-03-20 13:58:25,520:INFO:           wurlitzer: Not installed
2024-03-20 13:58:25,520:INFO:PyCaret optional dependencies:
2024-03-20 13:58:25,569:INFO:                shap: Not installed
2024-03-20 13:58:25,569:INFO:           interpret: Not installed
2024-03-20 13:58:25,569:INFO:                umap: Not installed
2024-03-20 13:58:25,569:INFO:     ydata_profiling: Not installed
2024-03-20 13:58:25,569:INFO:  explainerdashboard: Not installed
2024-03-20 13:58:25,569:INFO:             autoviz: Not installed
2024-03-20 13:58:25,569:INFO:           fairlearn: Not installed
2024-03-20 13:58:25,569:INFO:          deepchecks: Not installed
2024-03-20 13:58:25,569:INFO:             xgboost: 2.0.3
2024-03-20 13:58:25,569:INFO:            catboost: Not installed
2024-03-20 13:58:25,569:INFO:              kmodes: Not installed
2024-03-20 13:58:25,569:INFO:             mlxtend: Not installed
2024-03-20 13:58:25,569:INFO:       statsforecast: Not installed
2024-03-20 13:58:25,569:INFO:        tune_sklearn: Not installed
2024-03-20 13:58:25,569:INFO:                 ray: Not installed
2024-03-20 13:58:25,569:INFO:            hyperopt: Not installed
2024-03-20 13:58:25,569:INFO:              optuna: Not installed
2024-03-20 13:58:25,569:INFO:               skopt: Not installed
2024-03-20 13:58:25,569:INFO:              mlflow: Not installed
2024-03-20 13:58:25,569:INFO:              gradio: Not installed
2024-03-20 13:58:25,569:INFO:             fastapi: Not installed
2024-03-20 13:58:25,569:INFO:             uvicorn: Not installed
2024-03-20 13:58:25,569:INFO:              m2cgen: Not installed
2024-03-20 13:58:25,569:INFO:           evidently: Not installed
2024-03-20 13:58:25,569:INFO:               fugue: Not installed
2024-03-20 13:58:25,569:INFO:           streamlit: 1.32.2
2024-03-20 13:58:25,569:INFO:             prophet: 1.1.5
2024-03-20 13:58:25,569:INFO:None
2024-03-20 13:58:25,569:INFO:Set up data.
2024-03-20 13:58:25,617:INFO:Set up folding strategy.
2024-03-20 13:58:25,617:INFO:Set up train/test split.
2024-03-20 13:58:25,662:INFO:Set up index.
2024-03-20 13:58:25,665:INFO:Assigning column types.
2024-03-20 13:58:25,687:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-03-20 13:58:25,721:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-20 13:58:25,725:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-20 13:58:25,753:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-20 13:58:25,755:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-20 13:58:25,792:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-20 13:58:25,792:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-20 13:58:25,812:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-20 13:58:25,812:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-20 13:58:25,812:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-03-20 13:58:25,847:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-20 13:58:25,868:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-20 13:58:25,875:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-20 13:58:25,910:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-20 13:58:25,930:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-20 13:58:25,930:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-20 13:58:25,930:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-03-20 13:58:25,986:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-20 13:58:25,986:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-20 13:58:26,042:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-20 13:58:26,042:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-20 13:58:26,052:INFO:Preparing preprocessing pipeline...
2024-03-20 13:58:26,056:INFO:Set up simple imputation.
2024-03-20 13:58:26,069:INFO:Set up encoding of categorical features.
2024-03-20 13:58:26,277:INFO:Finished creating preprocessing pipeline.
2024-03-20 13:58:26,291:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\admcn\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['attribute1', 'attribute2',
                                             'attribute3', 'attribute4',
                                             'attribute5', 'attribute6',
                                             'attribute7', 'attribute8',
                                             'attribute9'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_fe...
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['date', 'device'],
                                    transformer=TargetEncoder(cols=['date',
                                                                    'device'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-03-20 13:58:26,291:INFO:Creating final display dataframe.
2024-03-20 13:58:26,853:INFO:Setup _display_container:                     Description             Value
0                    Session id              3260
1                        Target           failure
2                   Target type            Binary
3           Original data shape      (124494, 12)
4        Transformed data shape      (124494, 12)
5   Transformed train set shape       (87145, 12)
6    Transformed test set shape       (37349, 12)
7              Numeric features                 9
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              170a
2024-03-20 13:58:26,923:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-20 13:58:26,923:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-20 13:58:26,981:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-20 13:58:26,983:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-20 13:58:26,985:INFO:setup() successfully completed in 2.23s...............
2024-03-20 13:58:47,880:INFO:Initializing compare_models()
2024-03-20 13:58:47,880:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002397C524510>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002397C524510>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-03-20 13:58:47,880:INFO:Checking exceptions
2024-03-20 13:58:47,900:INFO:Preparing display monitor
2024-03-20 13:58:47,915:INFO:Initializing Logistic Regression
2024-03-20 13:58:47,915:INFO:Total runtime is 0.0 minutes
2024-03-20 13:58:47,922:INFO:SubProcess create_model() called ==================================
2024-03-20 13:58:47,922:INFO:Initializing create_model()
2024-03-20 13:58:47,922:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002397C524510>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023902ADED50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 13:58:47,922:INFO:Checking exceptions
2024-03-20 13:58:47,922:INFO:Importing libraries
2024-03-20 13:58:47,922:INFO:Copying training dataset
2024-03-20 13:58:47,966:INFO:Defining folds
2024-03-20 13:58:47,967:INFO:Declaring metric variables
2024-03-20 13:58:47,969:INFO:Importing untrained model
2024-03-20 13:58:47,972:INFO:Logistic Regression Imported successfully
2024-03-20 13:58:47,978:INFO:Starting cross validation
2024-03-20 13:58:47,978:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 13:58:54,615:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:58:55,165:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:58:56,591:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:58:56,937:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:58:57,555:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:58:57,564:INFO:Calculating mean and std
2024-03-20 13:58:57,565:INFO:Creating metrics dataframe
2024-03-20 13:58:57,566:INFO:Uploading results into container
2024-03-20 13:58:57,567:INFO:Uploading model into container now
2024-03-20 13:58:57,567:INFO:_master_model_container: 1
2024-03-20 13:58:57,568:INFO:_display_container: 2
2024-03-20 13:58:57,568:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3260, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-03-20 13:58:57,568:INFO:create_model() successfully completed......................................
2024-03-20 13:58:57,669:INFO:SubProcess create_model() end ==================================
2024-03-20 13:58:57,669:INFO:Creating metrics dataframe
2024-03-20 13:58:57,673:INFO:Initializing K Neighbors Classifier
2024-03-20 13:58:57,673:INFO:Total runtime is 0.16263308922449748 minutes
2024-03-20 13:58:57,679:INFO:SubProcess create_model() called ==================================
2024-03-20 13:58:57,679:INFO:Initializing create_model()
2024-03-20 13:58:57,679:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002397C524510>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023902ADED50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 13:58:57,679:INFO:Checking exceptions
2024-03-20 13:58:57,679:INFO:Importing libraries
2024-03-20 13:58:57,680:INFO:Copying training dataset
2024-03-20 13:58:57,719:INFO:Defining folds
2024-03-20 13:58:57,719:INFO:Declaring metric variables
2024-03-20 13:58:57,721:INFO:Importing untrained model
2024-03-20 13:58:57,722:INFO:K Neighbors Classifier Imported successfully
2024-03-20 13:58:57,728:INFO:Starting cross validation
2024-03-20 13:58:57,729:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 13:58:59,398:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:58:59,410:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:58:59,426:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:58:59,495:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:58:59,524:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:58:59,664:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:58:59,730:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:58:59,749:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:02,675:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:02,706:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:02,718:INFO:Calculating mean and std
2024-03-20 13:59:02,718:INFO:Creating metrics dataframe
2024-03-20 13:59:02,718:INFO:Uploading results into container
2024-03-20 13:59:02,718:INFO:Uploading model into container now
2024-03-20 13:59:02,718:INFO:_master_model_container: 2
2024-03-20 13:59:02,718:INFO:_display_container: 2
2024-03-20 13:59:02,718:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-03-20 13:59:02,718:INFO:create_model() successfully completed......................................
2024-03-20 13:59:02,817:INFO:SubProcess create_model() end ==================================
2024-03-20 13:59:02,817:INFO:Creating metrics dataframe
2024-03-20 13:59:02,817:INFO:Initializing Naive Bayes
2024-03-20 13:59:02,832:INFO:Total runtime is 0.24860326846440634 minutes
2024-03-20 13:59:02,833:INFO:SubProcess create_model() called ==================================
2024-03-20 13:59:02,833:INFO:Initializing create_model()
2024-03-20 13:59:02,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002397C524510>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023902ADED50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 13:59:02,833:INFO:Checking exceptions
2024-03-20 13:59:02,833:INFO:Importing libraries
2024-03-20 13:59:02,833:INFO:Copying training dataset
2024-03-20 13:59:02,869:INFO:Defining folds
2024-03-20 13:59:02,869:INFO:Declaring metric variables
2024-03-20 13:59:02,869:INFO:Importing untrained model
2024-03-20 13:59:02,869:INFO:Naive Bayes Imported successfully
2024-03-20 13:59:02,881:INFO:Starting cross validation
2024-03-20 13:59:02,882:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 13:59:03,526:INFO:Calculating mean and std
2024-03-20 13:59:03,527:INFO:Creating metrics dataframe
2024-03-20 13:59:03,529:INFO:Uploading results into container
2024-03-20 13:59:03,529:INFO:Uploading model into container now
2024-03-20 13:59:03,530:INFO:_master_model_container: 3
2024-03-20 13:59:03,530:INFO:_display_container: 2
2024-03-20 13:59:03,530:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-03-20 13:59:03,530:INFO:create_model() successfully completed......................................
2024-03-20 13:59:03,616:INFO:SubProcess create_model() end ==================================
2024-03-20 13:59:03,616:INFO:Creating metrics dataframe
2024-03-20 13:59:03,633:INFO:Initializing Decision Tree Classifier
2024-03-20 13:59:03,633:INFO:Total runtime is 0.2619580705960592 minutes
2024-03-20 13:59:03,633:INFO:SubProcess create_model() called ==================================
2024-03-20 13:59:03,633:INFO:Initializing create_model()
2024-03-20 13:59:03,633:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002397C524510>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023902ADED50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 13:59:03,633:INFO:Checking exceptions
2024-03-20 13:59:03,633:INFO:Importing libraries
2024-03-20 13:59:03,633:INFO:Copying training dataset
2024-03-20 13:59:03,665:INFO:Defining folds
2024-03-20 13:59:03,665:INFO:Declaring metric variables
2024-03-20 13:59:03,665:INFO:Importing untrained model
2024-03-20 13:59:03,665:INFO:Decision Tree Classifier Imported successfully
2024-03-20 13:59:03,680:INFO:Starting cross validation
2024-03-20 13:59:03,680:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 13:59:04,395:INFO:Calculating mean and std
2024-03-20 13:59:04,395:INFO:Creating metrics dataframe
2024-03-20 13:59:04,395:INFO:Uploading results into container
2024-03-20 13:59:04,395:INFO:Uploading model into container now
2024-03-20 13:59:04,395:INFO:_master_model_container: 4
2024-03-20 13:59:04,395:INFO:_display_container: 2
2024-03-20 13:59:04,395:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=3260, splitter='best')
2024-03-20 13:59:04,395:INFO:create_model() successfully completed......................................
2024-03-20 13:59:04,478:INFO:SubProcess create_model() end ==================================
2024-03-20 13:59:04,478:INFO:Creating metrics dataframe
2024-03-20 13:59:04,485:INFO:Initializing SVM - Linear Kernel
2024-03-20 13:59:04,485:INFO:Total runtime is 0.2761539936065674 minutes
2024-03-20 13:59:04,491:INFO:SubProcess create_model() called ==================================
2024-03-20 13:59:04,491:INFO:Initializing create_model()
2024-03-20 13:59:04,491:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002397C524510>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023902ADED50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 13:59:04,491:INFO:Checking exceptions
2024-03-20 13:59:04,491:INFO:Importing libraries
2024-03-20 13:59:04,491:INFO:Copying training dataset
2024-03-20 13:59:04,519:INFO:Defining folds
2024-03-20 13:59:04,519:INFO:Declaring metric variables
2024-03-20 13:59:04,527:INFO:Importing untrained model
2024-03-20 13:59:04,527:INFO:SVM - Linear Kernel Imported successfully
2024-03-20 13:59:04,535:INFO:Starting cross validation
2024-03-20 13:59:04,535:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 13:59:06,035:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 13:59:06,042:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:06,049:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 13:59:06,055:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 13:59:06,055:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:06,062:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:06,084:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 13:59:06,096:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:06,158:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 13:59:06,166:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:06,312:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 13:59:06,327:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:06,464:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 13:59:06,471:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:06,617:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 13:59:06,617:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:06,663:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 13:59:06,663:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 13:59:06,663:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:06,663:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:06,663:INFO:Calculating mean and std
2024-03-20 13:59:06,663:INFO:Creating metrics dataframe
2024-03-20 13:59:06,679:INFO:Uploading results into container
2024-03-20 13:59:06,679:INFO:Uploading model into container now
2024-03-20 13:59:06,679:INFO:_master_model_container: 5
2024-03-20 13:59:06,679:INFO:_display_container: 2
2024-03-20 13:59:06,679:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3260, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-03-20 13:59:06,679:INFO:create_model() successfully completed......................................
2024-03-20 13:59:06,768:INFO:SubProcess create_model() end ==================================
2024-03-20 13:59:06,768:INFO:Creating metrics dataframe
2024-03-20 13:59:06,768:INFO:Initializing Ridge Classifier
2024-03-20 13:59:06,768:INFO:Total runtime is 0.31421528657277426 minutes
2024-03-20 13:59:06,768:INFO:SubProcess create_model() called ==================================
2024-03-20 13:59:06,768:INFO:Initializing create_model()
2024-03-20 13:59:06,768:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002397C524510>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023902ADED50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 13:59:06,768:INFO:Checking exceptions
2024-03-20 13:59:06,768:INFO:Importing libraries
2024-03-20 13:59:06,768:INFO:Copying training dataset
2024-03-20 13:59:06,804:INFO:Defining folds
2024-03-20 13:59:06,804:INFO:Declaring metric variables
2024-03-20 13:59:06,819:INFO:Importing untrained model
2024-03-20 13:59:06,819:INFO:Ridge Classifier Imported successfully
2024-03-20 13:59:06,828:INFO:Starting cross validation
2024-03-20 13:59:06,831:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 13:59:07,216:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.40333e-21): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-20 13:59:07,231:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.43354e-21): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-20 13:59:07,247:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.44266e-21): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-20 13:59:07,264:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 13:59:07,264:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:07,264:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 13:59:07,278:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.2444e-21): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-20 13:59:07,278:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:07,278:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 13:59:07,294:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:07,294:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.34112e-21): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-20 13:59:07,309:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 13:59:07,325:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.34706e-21): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-20 13:59:07,325:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 13:59:07,341:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:07,341:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.39181e-21): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-20 13:59:07,358:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 13:59:07,373:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 13:59:07,373:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:07,373:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.35322e-21): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-20 13:59:07,373:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:07,373:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.28702e-21): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-20 13:59:07,404:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 13:59:07,408:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.36528e-21): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-20 13:59:07,410:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 13:59:07,410:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:07,417:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:07,428:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 13:59:07,429:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:07,429:INFO:Calculating mean and std
2024-03-20 13:59:07,429:INFO:Creating metrics dataframe
2024-03-20 13:59:07,429:INFO:Uploading results into container
2024-03-20 13:59:07,429:INFO:Uploading model into container now
2024-03-20 13:59:07,429:INFO:_master_model_container: 6
2024-03-20 13:59:07,443:INFO:_display_container: 2
2024-03-20 13:59:07,443:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3260, solver='auto',
                tol=0.0001)
2024-03-20 13:59:07,443:INFO:create_model() successfully completed......................................
2024-03-20 13:59:07,526:INFO:SubProcess create_model() end ==================================
2024-03-20 13:59:07,526:INFO:Creating metrics dataframe
2024-03-20 13:59:07,527:INFO:Initializing Random Forest Classifier
2024-03-20 13:59:07,527:INFO:Total runtime is 0.32685366868972776 minutes
2024-03-20 13:59:07,533:INFO:SubProcess create_model() called ==================================
2024-03-20 13:59:07,533:INFO:Initializing create_model()
2024-03-20 13:59:07,533:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002397C524510>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023902ADED50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 13:59:07,533:INFO:Checking exceptions
2024-03-20 13:59:07,533:INFO:Importing libraries
2024-03-20 13:59:07,533:INFO:Copying training dataset
2024-03-20 13:59:07,568:INFO:Defining folds
2024-03-20 13:59:07,568:INFO:Declaring metric variables
2024-03-20 13:59:07,568:INFO:Importing untrained model
2024-03-20 13:59:07,568:INFO:Random Forest Classifier Imported successfully
2024-03-20 13:59:07,577:INFO:Starting cross validation
2024-03-20 13:59:07,577:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 13:59:14,612:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:14,652:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:14,652:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:14,665:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:14,672:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:14,794:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:14,794:INFO:Calculating mean and std
2024-03-20 13:59:14,794:INFO:Creating metrics dataframe
2024-03-20 13:59:14,809:INFO:Uploading results into container
2024-03-20 13:59:14,809:INFO:Uploading model into container now
2024-03-20 13:59:14,809:INFO:_master_model_container: 7
2024-03-20 13:59:14,809:INFO:_display_container: 2
2024-03-20 13:59:14,811:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3260, verbose=0,
                       warm_start=False)
2024-03-20 13:59:14,811:INFO:create_model() successfully completed......................................
2024-03-20 13:59:14,897:INFO:SubProcess create_model() end ==================================
2024-03-20 13:59:14,897:INFO:Creating metrics dataframe
2024-03-20 13:59:14,916:INFO:Initializing Quadratic Discriminant Analysis
2024-03-20 13:59:14,916:INFO:Total runtime is 0.45000900427500407 minutes
2024-03-20 13:59:14,923:INFO:SubProcess create_model() called ==================================
2024-03-20 13:59:14,924:INFO:Initializing create_model()
2024-03-20 13:59:14,924:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002397C524510>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023902ADED50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 13:59:14,924:INFO:Checking exceptions
2024-03-20 13:59:14,924:INFO:Importing libraries
2024-03-20 13:59:14,924:INFO:Copying training dataset
2024-03-20 13:59:14,956:INFO:Defining folds
2024-03-20 13:59:14,956:INFO:Declaring metric variables
2024-03-20 13:59:14,956:INFO:Importing untrained model
2024-03-20 13:59:14,965:INFO:Quadratic Discriminant Analysis Imported successfully
2024-03-20 13:59:14,970:INFO:Starting cross validation
2024-03-20 13:59:14,971:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 13:59:15,375:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-20 13:59:15,375:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-20 13:59:15,406:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-20 13:59:15,429:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-20 13:59:15,470:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-20 13:59:15,485:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-20 13:59:15,514:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-20 13:59:15,540:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-20 13:59:15,563:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-20 13:59:15,576:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-20 13:59:15,658:INFO:Calculating mean and std
2024-03-20 13:59:15,658:INFO:Creating metrics dataframe
2024-03-20 13:59:15,658:INFO:Uploading results into container
2024-03-20 13:59:15,658:INFO:Uploading model into container now
2024-03-20 13:59:15,658:INFO:_master_model_container: 8
2024-03-20 13:59:15,658:INFO:_display_container: 2
2024-03-20 13:59:15,658:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-03-20 13:59:15,658:INFO:create_model() successfully completed......................................
2024-03-20 13:59:15,749:INFO:SubProcess create_model() end ==================================
2024-03-20 13:59:15,749:INFO:Creating metrics dataframe
2024-03-20 13:59:15,764:INFO:Initializing Ada Boost Classifier
2024-03-20 13:59:15,764:INFO:Total runtime is 0.46414552132288617 minutes
2024-03-20 13:59:15,764:INFO:SubProcess create_model() called ==================================
2024-03-20 13:59:15,764:INFO:Initializing create_model()
2024-03-20 13:59:15,764:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002397C524510>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023902ADED50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 13:59:15,764:INFO:Checking exceptions
2024-03-20 13:59:15,764:INFO:Importing libraries
2024-03-20 13:59:15,764:INFO:Copying training dataset
2024-03-20 13:59:15,796:INFO:Defining folds
2024-03-20 13:59:15,796:INFO:Declaring metric variables
2024-03-20 13:59:15,803:INFO:Importing untrained model
2024-03-20 13:59:15,805:INFO:Ada Boost Classifier Imported successfully
2024-03-20 13:59:15,810:INFO:Starting cross validation
2024-03-20 13:59:15,811:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 13:59:16,096:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-20 13:59:16,145:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-20 13:59:16,181:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-20 13:59:16,202:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-20 13:59:16,229:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-20 13:59:16,237:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-20 13:59:16,271:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-20 13:59:16,287:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-20 13:59:16,318:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-20 13:59:16,354:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-20 13:59:19,928:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:20,214:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:20,295:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:20,307:INFO:Calculating mean and std
2024-03-20 13:59:20,308:INFO:Creating metrics dataframe
2024-03-20 13:59:20,309:INFO:Uploading results into container
2024-03-20 13:59:20,310:INFO:Uploading model into container now
2024-03-20 13:59:20,310:INFO:_master_model_container: 9
2024-03-20 13:59:20,310:INFO:_display_container: 2
2024-03-20 13:59:20,310:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3260)
2024-03-20 13:59:20,310:INFO:create_model() successfully completed......................................
2024-03-20 13:59:20,404:INFO:SubProcess create_model() end ==================================
2024-03-20 13:59:20,404:INFO:Creating metrics dataframe
2024-03-20 13:59:20,408:INFO:Initializing Gradient Boosting Classifier
2024-03-20 13:59:20,408:INFO:Total runtime is 0.5415488560994466 minutes
2024-03-20 13:59:20,408:INFO:SubProcess create_model() called ==================================
2024-03-20 13:59:20,408:INFO:Initializing create_model()
2024-03-20 13:59:20,408:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002397C524510>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023902ADED50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 13:59:20,408:INFO:Checking exceptions
2024-03-20 13:59:20,408:INFO:Importing libraries
2024-03-20 13:59:20,408:INFO:Copying training dataset
2024-03-20 13:59:20,449:INFO:Defining folds
2024-03-20 13:59:20,449:INFO:Declaring metric variables
2024-03-20 13:59:20,451:INFO:Importing untrained model
2024-03-20 13:59:20,451:INFO:Gradient Boosting Classifier Imported successfully
2024-03-20 13:59:20,459:INFO:Starting cross validation
2024-03-20 13:59:20,460:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 13:59:35,355:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:38,805:INFO:Calculating mean and std
2024-03-20 13:59:38,806:INFO:Creating metrics dataframe
2024-03-20 13:59:38,807:INFO:Uploading results into container
2024-03-20 13:59:38,807:INFO:Uploading model into container now
2024-03-20 13:59:38,808:INFO:_master_model_container: 10
2024-03-20 13:59:38,808:INFO:_display_container: 2
2024-03-20 13:59:38,808:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3260, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-20 13:59:38,808:INFO:create_model() successfully completed......................................
2024-03-20 13:59:38,906:INFO:SubProcess create_model() end ==================================
2024-03-20 13:59:38,906:INFO:Creating metrics dataframe
2024-03-20 13:59:38,906:INFO:Initializing Linear Discriminant Analysis
2024-03-20 13:59:38,906:INFO:Total runtime is 0.8498422543207804 minutes
2024-03-20 13:59:38,906:INFO:SubProcess create_model() called ==================================
2024-03-20 13:59:38,906:INFO:Initializing create_model()
2024-03-20 13:59:38,906:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002397C524510>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023902ADED50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 13:59:38,906:INFO:Checking exceptions
2024-03-20 13:59:38,906:INFO:Importing libraries
2024-03-20 13:59:38,906:INFO:Copying training dataset
2024-03-20 13:59:38,961:INFO:Defining folds
2024-03-20 13:59:38,961:INFO:Declaring metric variables
2024-03-20 13:59:38,964:INFO:Importing untrained model
2024-03-20 13:59:38,967:INFO:Linear Discriminant Analysis Imported successfully
2024-03-20 13:59:38,974:INFO:Starting cross validation
2024-03-20 13:59:38,975:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 13:59:39,796:INFO:Calculating mean and std
2024-03-20 13:59:39,796:INFO:Creating metrics dataframe
2024-03-20 13:59:39,796:INFO:Uploading results into container
2024-03-20 13:59:39,796:INFO:Uploading model into container now
2024-03-20 13:59:39,796:INFO:_master_model_container: 11
2024-03-20 13:59:39,796:INFO:_display_container: 2
2024-03-20 13:59:39,804:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-03-20 13:59:39,804:INFO:create_model() successfully completed......................................
2024-03-20 13:59:39,894:INFO:SubProcess create_model() end ==================================
2024-03-20 13:59:39,894:INFO:Creating metrics dataframe
2024-03-20 13:59:39,901:INFO:Initializing Extra Trees Classifier
2024-03-20 13:59:39,901:INFO:Total runtime is 0.8664201498031616 minutes
2024-03-20 13:59:39,909:INFO:SubProcess create_model() called ==================================
2024-03-20 13:59:39,909:INFO:Initializing create_model()
2024-03-20 13:59:39,909:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002397C524510>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023902ADED50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 13:59:39,909:INFO:Checking exceptions
2024-03-20 13:59:39,909:INFO:Importing libraries
2024-03-20 13:59:39,909:INFO:Copying training dataset
2024-03-20 13:59:39,949:INFO:Defining folds
2024-03-20 13:59:39,949:INFO:Declaring metric variables
2024-03-20 13:59:39,949:INFO:Importing untrained model
2024-03-20 13:59:39,958:INFO:Extra Trees Classifier Imported successfully
2024-03-20 13:59:39,964:INFO:Starting cross validation
2024-03-20 13:59:39,965:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 13:59:42,963:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:42,964:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:43,005:INFO:Calculating mean and std
2024-03-20 13:59:43,006:INFO:Creating metrics dataframe
2024-03-20 13:59:43,008:INFO:Uploading results into container
2024-03-20 13:59:43,008:INFO:Uploading model into container now
2024-03-20 13:59:43,009:INFO:_master_model_container: 12
2024-03-20 13:59:43,009:INFO:_display_container: 2
2024-03-20 13:59:43,009:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=3260, verbose=0,
                     warm_start=False)
2024-03-20 13:59:43,009:INFO:create_model() successfully completed......................................
2024-03-20 13:59:43,104:INFO:SubProcess create_model() end ==================================
2024-03-20 13:59:43,104:INFO:Creating metrics dataframe
2024-03-20 13:59:43,115:INFO:Initializing Extreme Gradient Boosting
2024-03-20 13:59:43,115:INFO:Total runtime is 0.9199868480364481 minutes
2024-03-20 13:59:43,118:INFO:SubProcess create_model() called ==================================
2024-03-20 13:59:43,118:INFO:Initializing create_model()
2024-03-20 13:59:43,118:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002397C524510>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023902ADED50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 13:59:43,118:INFO:Checking exceptions
2024-03-20 13:59:43,118:INFO:Importing libraries
2024-03-20 13:59:43,118:INFO:Copying training dataset
2024-03-20 13:59:43,159:INFO:Defining folds
2024-03-20 13:59:43,159:INFO:Declaring metric variables
2024-03-20 13:59:43,162:INFO:Importing untrained model
2024-03-20 13:59:43,165:INFO:Extreme Gradient Boosting Imported successfully
2024-03-20 13:59:43,173:INFO:Starting cross validation
2024-03-20 13:59:43,174:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 13:59:44,750:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:44,769:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:44,859:INFO:Calculating mean and std
2024-03-20 13:59:44,859:INFO:Creating metrics dataframe
2024-03-20 13:59:44,865:INFO:Uploading results into container
2024-03-20 13:59:44,866:INFO:Uploading model into container now
2024-03-20 13:59:44,866:INFO:_master_model_container: 13
2024-03-20 13:59:44,866:INFO:_display_container: 2
2024-03-20 13:59:44,866:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-03-20 13:59:44,866:INFO:create_model() successfully completed......................................
2024-03-20 13:59:44,970:INFO:SubProcess create_model() end ==================================
2024-03-20 13:59:44,970:INFO:Creating metrics dataframe
2024-03-20 13:59:44,977:INFO:Initializing Light Gradient Boosting Machine
2024-03-20 13:59:44,977:INFO:Total runtime is 0.9510242780049641 minutes
2024-03-20 13:59:44,977:INFO:SubProcess create_model() called ==================================
2024-03-20 13:59:44,977:INFO:Initializing create_model()
2024-03-20 13:59:44,977:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002397C524510>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023902ADED50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 13:59:44,977:INFO:Checking exceptions
2024-03-20 13:59:44,977:INFO:Importing libraries
2024-03-20 13:59:44,977:INFO:Copying training dataset
2024-03-20 13:59:45,026:INFO:Defining folds
2024-03-20 13:59:45,026:INFO:Declaring metric variables
2024-03-20 13:59:45,029:INFO:Importing untrained model
2024-03-20 13:59:45,032:INFO:Light Gradient Boosting Machine Imported successfully
2024-03-20 13:59:45,035:INFO:Starting cross validation
2024-03-20 13:59:45,039:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 13:59:50,837:INFO:Calculating mean and std
2024-03-20 13:59:50,851:INFO:Creating metrics dataframe
2024-03-20 13:59:50,853:INFO:Uploading results into container
2024-03-20 13:59:50,853:INFO:Uploading model into container now
2024-03-20 13:59:50,853:INFO:_master_model_container: 14
2024-03-20 13:59:50,853:INFO:_display_container: 2
2024-03-20 13:59:50,856:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3260, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-03-20 13:59:50,856:INFO:create_model() successfully completed......................................
2024-03-20 13:59:50,974:INFO:SubProcess create_model() end ==================================
2024-03-20 13:59:50,974:INFO:Creating metrics dataframe
2024-03-20 13:59:50,998:INFO:Initializing Dummy Classifier
2024-03-20 13:59:50,998:INFO:Total runtime is 1.0513738552729288 minutes
2024-03-20 13:59:50,998:INFO:SubProcess create_model() called ==================================
2024-03-20 13:59:50,998:INFO:Initializing create_model()
2024-03-20 13:59:50,998:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002397C524510>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023902ADED50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 13:59:50,998:INFO:Checking exceptions
2024-03-20 13:59:50,998:INFO:Importing libraries
2024-03-20 13:59:50,998:INFO:Copying training dataset
2024-03-20 13:59:51,053:INFO:Defining folds
2024-03-20 13:59:51,053:INFO:Declaring metric variables
2024-03-20 13:59:51,060:INFO:Importing untrained model
2024-03-20 13:59:51,060:INFO:Dummy Classifier Imported successfully
2024-03-20 13:59:51,070:INFO:Starting cross validation
2024-03-20 13:59:51,070:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 13:59:51,555:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:51,586:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:51,589:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:51,592:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:51,618:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:51,637:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:51,682:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:51,708:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:51,756:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:51,758:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 13:59:51,762:INFO:Calculating mean and std
2024-03-20 13:59:51,762:INFO:Creating metrics dataframe
2024-03-20 13:59:51,762:INFO:Uploading results into container
2024-03-20 13:59:51,762:INFO:Uploading model into container now
2024-03-20 13:59:51,762:INFO:_master_model_container: 15
2024-03-20 13:59:51,762:INFO:_display_container: 2
2024-03-20 13:59:51,774:INFO:DummyClassifier(constant=None, random_state=3260, strategy='prior')
2024-03-20 13:59:51,774:INFO:create_model() successfully completed......................................
2024-03-20 13:59:51,857:INFO:SubProcess create_model() end ==================================
2024-03-20 13:59:51,857:INFO:Creating metrics dataframe
2024-03-20 13:59:51,891:INFO:Initializing create_model()
2024-03-20 13:59:51,891:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002397C524510>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 13:59:51,891:INFO:Checking exceptions
2024-03-20 13:59:51,893:INFO:Importing libraries
2024-03-20 13:59:51,893:INFO:Copying training dataset
2024-03-20 13:59:51,944:INFO:Defining folds
2024-03-20 13:59:51,944:INFO:Declaring metric variables
2024-03-20 13:59:51,945:INFO:Importing untrained model
2024-03-20 13:59:51,945:INFO:Declaring custom model
2024-03-20 13:59:51,945:INFO:K Neighbors Classifier Imported successfully
2024-03-20 13:59:51,945:INFO:Cross validation set to False
2024-03-20 13:59:51,945:INFO:Fitting Model
2024-03-20 13:59:52,361:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-03-20 13:59:52,361:INFO:create_model() successfully completed......................................
2024-03-20 13:59:52,485:INFO:_master_model_container: 15
2024-03-20 13:59:52,485:INFO:_display_container: 2
2024-03-20 13:59:52,486:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-03-20 13:59:52,486:INFO:compare_models() successfully completed......................................
2024-03-20 14:59:34,567:INFO:PyCaret ClassificationExperiment
2024-03-20 14:59:34,567:INFO:Logging name: clf-default-name
2024-03-20 14:59:34,567:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-03-20 14:59:34,567:INFO:version 3.3.0
2024-03-20 14:59:34,567:INFO:Initializing setup()
2024-03-20 14:59:34,567:INFO:self.USI: 4da4
2024-03-20 14:59:34,567:INFO:self._variable_keys: {'X_test', 'html_param', 'gpu_param', 'log_plots_param', 'is_multiclass', 'seed', 'fold_generator', '_ml_usecase', 'exp_id', 'idx', 'exp_name_log', 'n_jobs_param', 'fold_shuffle_param', '_available_plots', 'USI', 'target_param', 'logging_param', 'X', 'y_test', 'fix_imbalance', 'X_train', 'gpu_n_jobs_param', 'pipeline', 'y', 'fold_groups_param', 'y_train', 'data', 'memory'}
2024-03-20 14:59:34,567:INFO:Checking environment
2024-03-20 14:59:34,567:INFO:python_version: 3.11.5
2024-03-20 14:59:34,567:INFO:python_build: ('main', 'Sep 11 2023 13:26:23')
2024-03-20 14:59:34,567:INFO:machine: AMD64
2024-03-20 14:59:34,567:INFO:platform: Windows-10-10.0.22621-SP0
2024-03-20 14:59:34,567:INFO:Memory: svmem(total=34128322560, available=18523680768, percent=45.7, used=15604641792, free=18523680768)
2024-03-20 14:59:34,568:INFO:Physical Core: 6
2024-03-20 14:59:34,568:INFO:Logical Core: 12
2024-03-20 14:59:34,568:INFO:Checking libraries
2024-03-20 14:59:34,568:INFO:System:
2024-03-20 14:59:34,568:INFO:    python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]
2024-03-20 14:59:34,568:INFO:executable: C:\Users\admcn\anaconda3\python.exe
2024-03-20 14:59:34,568:INFO:   machine: Windows-10-10.0.22621-SP0
2024-03-20 14:59:34,568:INFO:PyCaret required dependencies:
2024-03-20 14:59:34,568:INFO:                 pip: 23.2.1
2024-03-20 14:59:34,568:INFO:          setuptools: 68.0.0
2024-03-20 14:59:34,568:INFO:             pycaret: 3.3.0
2024-03-20 14:59:34,568:INFO:             IPython: 8.15.0
2024-03-20 14:59:34,568:INFO:          ipywidgets: 8.0.4
2024-03-20 14:59:34,568:INFO:                tqdm: 4.65.0
2024-03-20 14:59:34,568:INFO:               numpy: 1.24.3
2024-03-20 14:59:34,568:INFO:              pandas: 2.1.4
2024-03-20 14:59:34,568:INFO:              jinja2: 3.1.2
2024-03-20 14:59:34,568:INFO:               scipy: 1.11.1
2024-03-20 14:59:34,568:INFO:              joblib: 1.2.0
2024-03-20 14:59:34,568:INFO:             sklearn: 1.4.1.post1
2024-03-20 14:59:34,568:INFO:                pyod: 1.1.3
2024-03-20 14:59:34,568:INFO:            imblearn: 0.12.0
2024-03-20 14:59:34,568:INFO:   category_encoders: 2.6.3
2024-03-20 14:59:34,568:INFO:            lightgbm: 4.3.0
2024-03-20 14:59:34,569:INFO:               numba: 0.57.1
2024-03-20 14:59:34,569:INFO:            requests: 2.31.0
2024-03-20 14:59:34,569:INFO:          matplotlib: 3.7.2
2024-03-20 14:59:34,569:INFO:          scikitplot: 0.3.7
2024-03-20 14:59:34,569:INFO:         yellowbrick: 1.5
2024-03-20 14:59:34,569:INFO:              plotly: 5.20.0
2024-03-20 14:59:34,569:INFO:    plotly-resampler: Not installed
2024-03-20 14:59:34,569:INFO:             kaleido: 0.2.1
2024-03-20 14:59:34,569:INFO:           schemdraw: 0.15
2024-03-20 14:59:34,569:INFO:         statsmodels: 0.14.0
2024-03-20 14:59:34,569:INFO:              sktime: 0.27.0
2024-03-20 14:59:34,569:INFO:               tbats: 1.1.3
2024-03-20 14:59:34,569:INFO:            pmdarima: 2.0.4
2024-03-20 14:59:34,569:INFO:              psutil: 5.9.0
2024-03-20 14:59:34,569:INFO:          markupsafe: 2.1.1
2024-03-20 14:59:34,569:INFO:             pickle5: Not installed
2024-03-20 14:59:34,569:INFO:         cloudpickle: 2.2.1
2024-03-20 14:59:34,569:INFO:         deprecation: 2.1.0
2024-03-20 14:59:34,569:INFO:              xxhash: 2.0.2
2024-03-20 14:59:34,569:INFO:           wurlitzer: Not installed
2024-03-20 14:59:34,569:INFO:PyCaret optional dependencies:
2024-03-20 14:59:34,569:INFO:                shap: Not installed
2024-03-20 14:59:34,569:INFO:           interpret: Not installed
2024-03-20 14:59:34,569:INFO:                umap: Not installed
2024-03-20 14:59:34,569:INFO:     ydata_profiling: Not installed
2024-03-20 14:59:34,569:INFO:  explainerdashboard: Not installed
2024-03-20 14:59:34,569:INFO:             autoviz: Not installed
2024-03-20 14:59:34,569:INFO:           fairlearn: Not installed
2024-03-20 14:59:34,569:INFO:          deepchecks: Not installed
2024-03-20 14:59:34,570:INFO:             xgboost: 2.0.3
2024-03-20 14:59:34,570:INFO:            catboost: Not installed
2024-03-20 14:59:34,570:INFO:              kmodes: Not installed
2024-03-20 14:59:34,570:INFO:             mlxtend: Not installed
2024-03-20 14:59:34,570:INFO:       statsforecast: Not installed
2024-03-20 14:59:34,570:INFO:        tune_sklearn: Not installed
2024-03-20 14:59:34,570:INFO:                 ray: Not installed
2024-03-20 14:59:34,570:INFO:            hyperopt: Not installed
2024-03-20 14:59:34,570:INFO:              optuna: Not installed
2024-03-20 14:59:34,570:INFO:               skopt: Not installed
2024-03-20 14:59:34,570:INFO:              mlflow: Not installed
2024-03-20 14:59:34,570:INFO:              gradio: Not installed
2024-03-20 14:59:34,570:INFO:             fastapi: Not installed
2024-03-20 14:59:34,570:INFO:             uvicorn: Not installed
2024-03-20 14:59:34,570:INFO:              m2cgen: Not installed
2024-03-20 14:59:34,570:INFO:           evidently: Not installed
2024-03-20 14:59:34,570:INFO:               fugue: Not installed
2024-03-20 14:59:34,570:INFO:           streamlit: 1.32.2
2024-03-20 14:59:34,570:INFO:             prophet: 1.1.5
2024-03-20 14:59:34,570:INFO:None
2024-03-20 14:59:34,570:INFO:Set up data.
2024-03-20 14:59:34,594:INFO:Set up folding strategy.
2024-03-20 14:59:34,595:INFO:Set up train/test split.
2024-03-20 14:59:34,637:INFO:Set up index.
2024-03-20 14:59:34,639:INFO:Assigning column types.
2024-03-20 14:59:34,660:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-03-20 14:59:34,708:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-20 14:59:34,709:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-20 14:59:34,728:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-20 14:59:34,735:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-20 14:59:34,770:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-03-20 14:59:34,770:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-20 14:59:34,791:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-20 14:59:34,797:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-20 14:59:34,798:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-03-20 14:59:34,832:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-20 14:59:34,853:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-20 14:59:34,853:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-20 14:59:34,887:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-03-20 14:59:34,908:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-20 14:59:34,908:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-20 14:59:34,908:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-03-20 14:59:34,964:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-20 14:59:34,964:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-20 14:59:35,011:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-20 14:59:35,011:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-20 14:59:35,026:INFO:Preparing preprocessing pipeline...
2024-03-20 14:59:35,026:INFO:Set up simple imputation.
2024-03-20 14:59:35,026:INFO:Set up encoding of categorical features.
2024-03-20 14:59:35,183:INFO:Finished creating preprocessing pipeline.
2024-03-20 14:59:35,187:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\admcn\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['attribute1', 'attribute2',
                                             'attribute3', 'attribute4',
                                             'attribute5', 'attribute6',
                                             'attribute7', 'attribute9', 'day',
                                             'month', 'year'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['device'],
                                    transformer=OneHotEncoder(cols=['device'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-03-20 14:59:35,187:INFO:Creating final display dataframe.
2024-03-20 14:59:35,541:INFO:Setup _display_container:                     Description             Value
0                    Session id               979
1                        Target           failure
2                   Target type            Binary
3           Original data shape       (91690, 13)
4        Transformed data shape       (91690, 15)
5   Transformed train set shape       (64182, 15)
6    Transformed test set shape       (27508, 15)
7              Numeric features                11
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              4da4
2024-03-20 14:59:35,616:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-20 14:59:35,616:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-20 14:59:35,673:INFO:Soft dependency imported: xgboost: 2.0.3
2024-03-20 14:59:35,673:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-03-20 14:59:35,680:INFO:setup() successfully completed in 1.12s...............
2024-03-20 14:59:47,412:INFO:Initializing compare_models()
2024-03-20 14:59:47,412:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239081B5750>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000239081B5750>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-03-20 14:59:47,412:INFO:Checking exceptions
2024-03-20 14:59:47,427:INFO:Preparing display monitor
2024-03-20 14:59:47,441:INFO:Initializing Logistic Regression
2024-03-20 14:59:47,441:INFO:Total runtime is 0.0 minutes
2024-03-20 14:59:47,441:INFO:SubProcess create_model() called ==================================
2024-03-20 14:59:47,441:INFO:Initializing create_model()
2024-03-20 14:59:47,441:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239081B5750>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023925820C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 14:59:47,441:INFO:Checking exceptions
2024-03-20 14:59:47,449:INFO:Importing libraries
2024-03-20 14:59:47,450:INFO:Copying training dataset
2024-03-20 14:59:47,474:INFO:Defining folds
2024-03-20 14:59:47,474:INFO:Declaring metric variables
2024-03-20 14:59:47,476:INFO:Importing untrained model
2024-03-20 14:59:47,480:INFO:Logistic Regression Imported successfully
2024-03-20 14:59:47,489:INFO:Starting cross validation
2024-03-20 14:59:47,490:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 14:59:53,270:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:53,286:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:53,319:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:53,334:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:53,422:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:53,423:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:53,424:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:53,431:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:53,432:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:53,434:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:53,435:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:53,443:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:53,453:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:53,464:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:53,466:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:53,475:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:53,485:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:53,496:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:53,496:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:53,506:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:53,518:INFO:Calculating mean and std
2024-03-20 14:59:53,520:INFO:Creating metrics dataframe
2024-03-20 14:59:53,522:INFO:Uploading results into container
2024-03-20 14:59:53,523:INFO:Uploading model into container now
2024-03-20 14:59:53,524:INFO:_master_model_container: 1
2024-03-20 14:59:53,524:INFO:_display_container: 2
2024-03-20 14:59:53,525:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=979, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-03-20 14:59:53,525:INFO:create_model() successfully completed......................................
2024-03-20 14:59:53,866:INFO:SubProcess create_model() end ==================================
2024-03-20 14:59:53,866:INFO:Creating metrics dataframe
2024-03-20 14:59:53,873:INFO:Initializing K Neighbors Classifier
2024-03-20 14:59:53,874:INFO:Total runtime is 0.10721435944239298 minutes
2024-03-20 14:59:53,874:INFO:SubProcess create_model() called ==================================
2024-03-20 14:59:53,874:INFO:Initializing create_model()
2024-03-20 14:59:53,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239081B5750>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023925820C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 14:59:53,877:INFO:Checking exceptions
2024-03-20 14:59:53,877:INFO:Importing libraries
2024-03-20 14:59:53,877:INFO:Copying training dataset
2024-03-20 14:59:53,904:INFO:Defining folds
2024-03-20 14:59:53,904:INFO:Declaring metric variables
2024-03-20 14:59:53,907:INFO:Importing untrained model
2024-03-20 14:59:53,909:INFO:K Neighbors Classifier Imported successfully
2024-03-20 14:59:53,911:INFO:Starting cross validation
2024-03-20 14:59:53,914:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 14:59:54,896:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:54,902:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:54,910:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:54,917:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:54,935:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:54,937:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:54,944:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:54,945:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:54,965:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:54,965:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:54,971:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:54,972:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:54,972:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:54,977:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:54,986:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:54,992:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:57,763:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:57,763:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:57,769:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:57,769:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:57,783:INFO:Calculating mean and std
2024-03-20 14:59:57,783:INFO:Creating metrics dataframe
2024-03-20 14:59:57,783:INFO:Uploading results into container
2024-03-20 14:59:57,783:INFO:Uploading model into container now
2024-03-20 14:59:57,783:INFO:_master_model_container: 2
2024-03-20 14:59:57,783:INFO:_display_container: 2
2024-03-20 14:59:57,783:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-03-20 14:59:57,783:INFO:create_model() successfully completed......................................
2024-03-20 14:59:58,061:INFO:SubProcess create_model() end ==================================
2024-03-20 14:59:58,061:INFO:Creating metrics dataframe
2024-03-20 14:59:58,069:INFO:Initializing Naive Bayes
2024-03-20 14:59:58,069:INFO:Total runtime is 0.17714636723200478 minutes
2024-03-20 14:59:58,074:INFO:SubProcess create_model() called ==================================
2024-03-20 14:59:58,074:INFO:Initializing create_model()
2024-03-20 14:59:58,074:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239081B5750>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023925820C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 14:59:58,074:INFO:Checking exceptions
2024-03-20 14:59:58,074:INFO:Importing libraries
2024-03-20 14:59:58,074:INFO:Copying training dataset
2024-03-20 14:59:58,102:INFO:Defining folds
2024-03-20 14:59:58,102:INFO:Declaring metric variables
2024-03-20 14:59:58,106:INFO:Importing untrained model
2024-03-20 14:59:58,108:INFO:Naive Bayes Imported successfully
2024-03-20 14:59:58,112:INFO:Starting cross validation
2024-03-20 14:59:58,113:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 14:59:58,395:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:58,402:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:58,408:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:58,416:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:58,423:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:58,423:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:58,436:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:58,437:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:58,451:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:58,459:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:58,462:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:58,462:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:58,462:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:58,481:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:58,482:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:58,486:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:58,489:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:58,492:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:58,506:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:58,510:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:58,517:INFO:Calculating mean and std
2024-03-20 14:59:58,519:INFO:Creating metrics dataframe
2024-03-20 14:59:58,520:INFO:Uploading results into container
2024-03-20 14:59:58,520:INFO:Uploading model into container now
2024-03-20 14:59:58,521:INFO:_master_model_container: 3
2024-03-20 14:59:58,521:INFO:_display_container: 2
2024-03-20 14:59:58,521:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-03-20 14:59:58,521:INFO:create_model() successfully completed......................................
2024-03-20 14:59:58,783:INFO:SubProcess create_model() end ==================================
2024-03-20 14:59:58,783:INFO:Creating metrics dataframe
2024-03-20 14:59:58,790:INFO:Initializing Decision Tree Classifier
2024-03-20 14:59:58,790:INFO:Total runtime is 0.1891542553901672 minutes
2024-03-20 14:59:58,790:INFO:SubProcess create_model() called ==================================
2024-03-20 14:59:58,790:INFO:Initializing create_model()
2024-03-20 14:59:58,790:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239081B5750>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023925820C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 14:59:58,790:INFO:Checking exceptions
2024-03-20 14:59:58,790:INFO:Importing libraries
2024-03-20 14:59:58,797:INFO:Copying training dataset
2024-03-20 14:59:58,822:INFO:Defining folds
2024-03-20 14:59:58,822:INFO:Declaring metric variables
2024-03-20 14:59:58,824:INFO:Importing untrained model
2024-03-20 14:59:58,827:INFO:Decision Tree Classifier Imported successfully
2024-03-20 14:59:58,832:INFO:Starting cross validation
2024-03-20 14:59:58,833:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 14:59:59,201:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:59,207:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:59,208:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:59,208:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:59,242:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:59,269:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:59,277:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:59,277:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:59,277:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:59,283:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 14:59:59,297:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 14:59:59,312:INFO:Calculating mean and std
2024-03-20 14:59:59,312:INFO:Creating metrics dataframe
2024-03-20 14:59:59,319:INFO:Uploading results into container
2024-03-20 14:59:59,320:INFO:Uploading model into container now
2024-03-20 14:59:59,320:INFO:_master_model_container: 4
2024-03-20 14:59:59,320:INFO:_display_container: 2
2024-03-20 14:59:59,320:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=979, splitter='best')
2024-03-20 14:59:59,320:INFO:create_model() successfully completed......................................
2024-03-20 14:59:59,588:INFO:SubProcess create_model() end ==================================
2024-03-20 14:59:59,588:INFO:Creating metrics dataframe
2024-03-20 14:59:59,595:INFO:Initializing SVM - Linear Kernel
2024-03-20 14:59:59,595:INFO:Total runtime is 0.202578330039978 minutes
2024-03-20 14:59:59,602:INFO:SubProcess create_model() called ==================================
2024-03-20 14:59:59,603:INFO:Initializing create_model()
2024-03-20 14:59:59,603:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239081B5750>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023925820C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 14:59:59,603:INFO:Checking exceptions
2024-03-20 14:59:59,603:INFO:Importing libraries
2024-03-20 14:59:59,603:INFO:Copying training dataset
2024-03-20 14:59:59,631:INFO:Defining folds
2024-03-20 14:59:59,631:INFO:Declaring metric variables
2024-03-20 14:59:59,633:INFO:Importing untrained model
2024-03-20 14:59:59,636:INFO:SVM - Linear Kernel Imported successfully
2024-03-20 14:59:59,640:INFO:Starting cross validation
2024-03-20 14:59:59,641:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 15:00:00,503:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 15:00:00,503:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:00,575:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 15:00:00,581:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 15:00:00,590:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:00,597:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:00,610:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 15:00:00,622:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:00,652:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 15:00:00,660:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 15:00:00,662:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:00,666:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:00,735:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 15:00:00,741:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:00,748:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 15:00:00,762:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:00,825:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 15:00:00,826:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:00,839:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 15:00:00,852:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:00,859:INFO:Calculating mean and std
2024-03-20 15:00:00,859:INFO:Creating metrics dataframe
2024-03-20 15:00:00,866:INFO:Uploading results into container
2024-03-20 15:00:00,866:INFO:Uploading model into container now
2024-03-20 15:00:00,866:INFO:_master_model_container: 5
2024-03-20 15:00:00,866:INFO:_display_container: 2
2024-03-20 15:00:00,866:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=979, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-03-20 15:00:00,866:INFO:create_model() successfully completed......................................
2024-03-20 15:00:01,171:INFO:SubProcess create_model() end ==================================
2024-03-20 15:00:01,171:INFO:Creating metrics dataframe
2024-03-20 15:00:01,179:INFO:Initializing Ridge Classifier
2024-03-20 15:00:01,179:INFO:Total runtime is 0.2289700945218404 minutes
2024-03-20 15:00:01,179:INFO:SubProcess create_model() called ==================================
2024-03-20 15:00:01,179:INFO:Initializing create_model()
2024-03-20 15:00:01,179:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239081B5750>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023925820C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 15:00:01,179:INFO:Checking exceptions
2024-03-20 15:00:01,179:INFO:Importing libraries
2024-03-20 15:00:01,179:INFO:Copying training dataset
2024-03-20 15:00:01,214:INFO:Defining folds
2024-03-20 15:00:01,214:INFO:Declaring metric variables
2024-03-20 15:00:01,217:INFO:Importing untrained model
2024-03-20 15:00:01,220:INFO:Ridge Classifier Imported successfully
2024-03-20 15:00:01,225:INFO:Starting cross validation
2024-03-20 15:00:01,226:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 15:00:01,492:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.48791e-21): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-20 15:00:01,499:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.49054e-21): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-20 15:00:01,508:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.48751e-21): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-20 15:00:01,513:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.48932e-21): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-20 15:00:01,528:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 15:00:01,528:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 15:00:01,544:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:01,544:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:01,544:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.48798e-21): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-20 15:00:01,544:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 15:00:01,544:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.49332e-21): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-20 15:00:01,544:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:01,544:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 15:00:01,560:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:01,575:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.49143e-21): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-20 15:00:01,588:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 15:00:01,590:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 15:00:01,595:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.48837e-21): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-20 15:00:01,598:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:01,598:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:01,603:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.4932e-21): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-20 15:00:01,610:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 15:00:01,617:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.49595e-21): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-03-20 15:00:01,617:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:01,631:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 15:00:01,638:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 15:00:01,638:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:01,647:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:01,652:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2024-03-20 15:00:01,658:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:01,665:INFO:Calculating mean and std
2024-03-20 15:00:01,671:INFO:Creating metrics dataframe
2024-03-20 15:00:01,673:INFO:Uploading results into container
2024-03-20 15:00:01,673:INFO:Uploading model into container now
2024-03-20 15:00:01,673:INFO:_master_model_container: 6
2024-03-20 15:00:01,673:INFO:_display_container: 2
2024-03-20 15:00:01,673:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=979, solver='auto',
                tol=0.0001)
2024-03-20 15:00:01,673:INFO:create_model() successfully completed......................................
2024-03-20 15:00:01,965:INFO:SubProcess create_model() end ==================================
2024-03-20 15:00:01,965:INFO:Creating metrics dataframe
2024-03-20 15:00:01,980:INFO:Initializing Random Forest Classifier
2024-03-20 15:00:01,980:INFO:Total runtime is 0.2423304716746012 minutes
2024-03-20 15:00:01,983:INFO:SubProcess create_model() called ==================================
2024-03-20 15:00:01,984:INFO:Initializing create_model()
2024-03-20 15:00:01,984:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239081B5750>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023925820C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 15:00:01,984:INFO:Checking exceptions
2024-03-20 15:00:01,984:INFO:Importing libraries
2024-03-20 15:00:01,984:INFO:Copying training dataset
2024-03-20 15:00:02,014:INFO:Defining folds
2024-03-20 15:00:02,014:INFO:Declaring metric variables
2024-03-20 15:00:02,017:INFO:Importing untrained model
2024-03-20 15:00:02,020:INFO:Random Forest Classifier Imported successfully
2024-03-20 15:00:02,021:INFO:Starting cross validation
2024-03-20 15:00:02,026:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 15:00:04,645:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:04,653:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:04,716:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:04,723:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:04,736:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:04,799:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:04,820:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:04,831:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:05,073:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:05,079:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:05,110:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:05,155:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:05,220:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:05,221:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:05,230:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:05,230:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:05,246:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:05,255:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:05,284:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:05,290:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:05,303:INFO:Calculating mean and std
2024-03-20 15:00:05,304:INFO:Creating metrics dataframe
2024-03-20 15:00:05,304:INFO:Uploading results into container
2024-03-20 15:00:05,304:INFO:Uploading model into container now
2024-03-20 15:00:05,304:INFO:_master_model_container: 7
2024-03-20 15:00:05,304:INFO:_display_container: 2
2024-03-20 15:00:05,309:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=979, verbose=0,
                       warm_start=False)
2024-03-20 15:00:05,309:INFO:create_model() successfully completed......................................
2024-03-20 15:00:05,652:INFO:SubProcess create_model() end ==================================
2024-03-20 15:00:05,652:INFO:Creating metrics dataframe
2024-03-20 15:00:05,664:INFO:Initializing Quadratic Discriminant Analysis
2024-03-20 15:00:05,664:INFO:Total runtime is 0.30372935136159257 minutes
2024-03-20 15:00:05,666:INFO:SubProcess create_model() called ==================================
2024-03-20 15:00:05,666:INFO:Initializing create_model()
2024-03-20 15:00:05,666:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239081B5750>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023925820C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 15:00:05,666:INFO:Checking exceptions
2024-03-20 15:00:05,666:INFO:Importing libraries
2024-03-20 15:00:05,666:INFO:Copying training dataset
2024-03-20 15:00:05,708:INFO:Defining folds
2024-03-20 15:00:05,708:INFO:Declaring metric variables
2024-03-20 15:00:05,708:INFO:Importing untrained model
2024-03-20 15:00:05,716:INFO:Quadratic Discriminant Analysis Imported successfully
2024-03-20 15:00:05,723:INFO:Starting cross validation
2024-03-20 15:00:05,724:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 15:00:06,029:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-20 15:00:06,037:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-20 15:00:06,089:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-20 15:00:06,103:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-03-20 15:00:06,103:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-03-20 15:00:06,105:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-03-20 15:00:06,105:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-20 15:00:06,105:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-03-20 15:00:06,105:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-03-20 15:00:06,110:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-03-20 15:00:06,117:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-20 15:00:06,138:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:06,145:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:06,154:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-03-20 15:00:06,154:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-03-20 15:00:06,155:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-03-20 15:00:06,162:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-03-20 15:00:06,162:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-03-20 15:00:06,166:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-03-20 15:00:06,175:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:06,175:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:06,175:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-20 15:00:06,175:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-03-20 15:00:06,180:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-03-20 15:00:06,180:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-03-20 15:00:06,188:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:06,195:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:06,199:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-20 15:00:06,202:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:06,202:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-20 15:00:06,207:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:06,208:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:06,216:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:06,222:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-03-20 15:00:06,222:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-03-20 15:00:06,222:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-03-20 15:00:06,235:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-20 15:00:06,236:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:06,242:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-03-20 15:00:06,242:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-03-20 15:00:06,242:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-03-20 15:00:06,245:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-03-20 15:00:06,247:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-03-20 15:00:06,247:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-03-20 15:00:06,249:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-03-20 15:00:06,250:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:06,257:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:06,262:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:06,263:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:06,263:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-03-20 15:00:06,263:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-03-20 15:00:06,263:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-03-20 15:00:06,270:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:06,270:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-03-20 15:00:06,270:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-03-20 15:00:06,270:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-03-20 15:00:06,277:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:06,283:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:06,289:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:06,290:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:06,305:INFO:Calculating mean and std
2024-03-20 15:00:06,305:INFO:Creating metrics dataframe
2024-03-20 15:00:06,310:INFO:Uploading results into container
2024-03-20 15:00:06,312:INFO:Uploading model into container now
2024-03-20 15:00:06,313:INFO:_master_model_container: 8
2024-03-20 15:00:06,313:INFO:_display_container: 2
2024-03-20 15:00:06,313:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-03-20 15:00:06,313:INFO:create_model() successfully completed......................................
2024-03-20 15:00:06,685:INFO:SubProcess create_model() end ==================================
2024-03-20 15:00:06,685:INFO:Creating metrics dataframe
2024-03-20 15:00:06,694:INFO:Initializing Ada Boost Classifier
2024-03-20 15:00:06,694:INFO:Total runtime is 0.3208850185076395 minutes
2024-03-20 15:00:06,695:INFO:SubProcess create_model() called ==================================
2024-03-20 15:00:06,695:INFO:Initializing create_model()
2024-03-20 15:00:06,695:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239081B5750>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023925820C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 15:00:06,695:INFO:Checking exceptions
2024-03-20 15:00:06,695:INFO:Importing libraries
2024-03-20 15:00:06,695:INFO:Copying training dataset
2024-03-20 15:00:06,734:INFO:Defining folds
2024-03-20 15:00:06,734:INFO:Declaring metric variables
2024-03-20 15:00:06,734:INFO:Importing untrained model
2024-03-20 15:00:06,743:INFO:Ada Boost Classifier Imported successfully
2024-03-20 15:00:06,748:INFO:Starting cross validation
2024-03-20 15:00:06,749:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 15:00:06,995:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-20 15:00:07,012:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-20 15:00:07,021:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-20 15:00:07,021:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-20 15:00:07,040:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-20 15:00:07,069:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-20 15:00:07,069:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-20 15:00:07,069:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-20 15:00:07,090:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-20 15:00:07,125:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-03-20 15:00:09,928:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:09,934:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:09,937:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:09,944:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:10,053:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:10,063:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:10,077:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:10,077:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:10,085:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:10,090:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:10,095:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:10,105:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:10,126:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:10,138:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:10,187:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:10,194:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:10,269:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:10,269:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:10,332:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:10,339:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:10,352:INFO:Calculating mean and std
2024-03-20 15:00:10,352:INFO:Creating metrics dataframe
2024-03-20 15:00:10,352:INFO:Uploading results into container
2024-03-20 15:00:10,352:INFO:Uploading model into container now
2024-03-20 15:00:10,352:INFO:_master_model_container: 9
2024-03-20 15:00:10,352:INFO:_display_container: 2
2024-03-20 15:00:10,352:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=979)
2024-03-20 15:00:10,352:INFO:create_model() successfully completed......................................
2024-03-20 15:00:10,672:INFO:SubProcess create_model() end ==================================
2024-03-20 15:00:10,672:INFO:Creating metrics dataframe
2024-03-20 15:00:10,681:INFO:Initializing Gradient Boosting Classifier
2024-03-20 15:00:10,681:INFO:Total runtime is 0.38733774820963535 minutes
2024-03-20 15:00:10,681:INFO:SubProcess create_model() called ==================================
2024-03-20 15:00:10,681:INFO:Initializing create_model()
2024-03-20 15:00:10,681:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239081B5750>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023925820C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 15:00:10,685:INFO:Checking exceptions
2024-03-20 15:00:10,685:INFO:Importing libraries
2024-03-20 15:00:10,685:INFO:Copying training dataset
2024-03-20 15:00:10,716:INFO:Defining folds
2024-03-20 15:00:10,716:INFO:Declaring metric variables
2024-03-20 15:00:10,719:INFO:Importing untrained model
2024-03-20 15:00:10,722:INFO:Gradient Boosting Classifier Imported successfully
2024-03-20 15:00:10,727:INFO:Starting cross validation
2024-03-20 15:00:10,728:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 15:00:21,152:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:21,445:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:21,485:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:21,553:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:21,562:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:21,576:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:21,582:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:21,589:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:21,616:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:21,652:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:21,700:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:21,713:INFO:Calculating mean and std
2024-03-20 15:00:21,713:INFO:Creating metrics dataframe
2024-03-20 15:00:21,713:INFO:Uploading results into container
2024-03-20 15:00:21,713:INFO:Uploading model into container now
2024-03-20 15:00:21,713:INFO:_master_model_container: 10
2024-03-20 15:00:21,713:INFO:_display_container: 2
2024-03-20 15:00:21,713:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=979, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-03-20 15:00:21,713:INFO:create_model() successfully completed......................................
2024-03-20 15:00:21,977:INFO:SubProcess create_model() end ==================================
2024-03-20 15:00:21,977:INFO:Creating metrics dataframe
2024-03-20 15:00:21,984:INFO:Initializing Linear Discriminant Analysis
2024-03-20 15:00:21,984:INFO:Total runtime is 0.5757263978322347 minutes
2024-03-20 15:00:21,991:INFO:SubProcess create_model() called ==================================
2024-03-20 15:00:21,991:INFO:Initializing create_model()
2024-03-20 15:00:21,991:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239081B5750>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023925820C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 15:00:21,991:INFO:Checking exceptions
2024-03-20 15:00:21,991:INFO:Importing libraries
2024-03-20 15:00:21,991:INFO:Copying training dataset
2024-03-20 15:00:22,025:INFO:Defining folds
2024-03-20 15:00:22,025:INFO:Declaring metric variables
2024-03-20 15:00:22,026:INFO:Importing untrained model
2024-03-20 15:00:22,026:INFO:Linear Discriminant Analysis Imported successfully
2024-03-20 15:00:22,035:INFO:Starting cross validation
2024-03-20 15:00:22,037:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 15:00:22,425:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:22,437:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:22,474:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:22,486:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:22,493:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:22,502:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:22,502:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:22,502:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:22,507:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:22,512:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:22,512:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:22,513:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:22,520:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:22,520:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:22,521:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:22,521:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:22,525:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:22,527:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:22,527:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:22,534:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:22,540:INFO:Calculating mean and std
2024-03-20 15:00:22,540:INFO:Creating metrics dataframe
2024-03-20 15:00:22,540:INFO:Uploading results into container
2024-03-20 15:00:22,546:INFO:Uploading model into container now
2024-03-20 15:00:22,546:INFO:_master_model_container: 11
2024-03-20 15:00:22,546:INFO:_display_container: 2
2024-03-20 15:00:22,546:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-03-20 15:00:22,546:INFO:create_model() successfully completed......................................
2024-03-20 15:00:22,819:INFO:SubProcess create_model() end ==================================
2024-03-20 15:00:22,819:INFO:Creating metrics dataframe
2024-03-20 15:00:22,826:INFO:Initializing Extra Trees Classifier
2024-03-20 15:00:22,826:INFO:Total runtime is 0.5897616505622864 minutes
2024-03-20 15:00:22,831:INFO:SubProcess create_model() called ==================================
2024-03-20 15:00:22,831:INFO:Initializing create_model()
2024-03-20 15:00:22,831:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239081B5750>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023925820C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 15:00:22,831:INFO:Checking exceptions
2024-03-20 15:00:22,831:INFO:Importing libraries
2024-03-20 15:00:22,831:INFO:Copying training dataset
2024-03-20 15:00:22,856:INFO:Defining folds
2024-03-20 15:00:22,856:INFO:Declaring metric variables
2024-03-20 15:00:22,859:INFO:Importing untrained model
2024-03-20 15:00:22,862:INFO:Extra Trees Classifier Imported successfully
2024-03-20 15:00:22,868:INFO:Starting cross validation
2024-03-20 15:00:22,869:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 15:00:24,215:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:24,235:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:24,679:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:24,689:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:24,696:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:24,701:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:24,702:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:24,706:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:24,711:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:24,712:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:24,713:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:24,735:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:24,747:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:24,747:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:24,748:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:24,757:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:24,757:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:24,763:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:24,775:INFO:Calculating mean and std
2024-03-20 15:00:24,776:INFO:Creating metrics dataframe
2024-03-20 15:00:24,776:INFO:Uploading results into container
2024-03-20 15:00:24,776:INFO:Uploading model into container now
2024-03-20 15:00:24,776:INFO:_master_model_container: 12
2024-03-20 15:00:24,776:INFO:_display_container: 2
2024-03-20 15:00:24,776:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=979, verbose=0,
                     warm_start=False)
2024-03-20 15:00:24,776:INFO:create_model() successfully completed......................................
2024-03-20 15:00:25,054:INFO:SubProcess create_model() end ==================================
2024-03-20 15:00:25,055:INFO:Creating metrics dataframe
2024-03-20 15:00:25,062:INFO:Initializing Extreme Gradient Boosting
2024-03-20 15:00:25,062:INFO:Total runtime is 0.6270237366358439 minutes
2024-03-20 15:00:25,064:INFO:SubProcess create_model() called ==================================
2024-03-20 15:00:25,064:INFO:Initializing create_model()
2024-03-20 15:00:25,064:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239081B5750>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023925820C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 15:00:25,064:INFO:Checking exceptions
2024-03-20 15:00:25,065:INFO:Importing libraries
2024-03-20 15:00:25,065:INFO:Copying training dataset
2024-03-20 15:00:25,091:INFO:Defining folds
2024-03-20 15:00:25,091:INFO:Declaring metric variables
2024-03-20 15:00:25,095:INFO:Importing untrained model
2024-03-20 15:00:25,097:INFO:Extreme Gradient Boosting Imported successfully
2024-03-20 15:00:25,105:INFO:Starting cross validation
2024-03-20 15:00:25,106:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 15:00:26,097:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:26,102:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:26,106:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:26,112:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:26,151:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:26,158:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:26,187:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:26,192:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:26,196:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:26,196:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:26,197:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:26,197:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:26,197:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:26,199:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:26,200:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:26,200:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:26,200:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:26,207:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:26,207:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:26,214:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:26,220:INFO:Calculating mean and std
2024-03-20 15:00:26,220:INFO:Creating metrics dataframe
2024-03-20 15:00:26,220:INFO:Uploading results into container
2024-03-20 15:00:26,220:INFO:Uploading model into container now
2024-03-20 15:00:26,220:INFO:_master_model_container: 13
2024-03-20 15:00:26,220:INFO:_display_container: 2
2024-03-20 15:00:26,226:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-03-20 15:00:26,226:INFO:create_model() successfully completed......................................
2024-03-20 15:00:26,491:INFO:SubProcess create_model() end ==================================
2024-03-20 15:00:26,491:INFO:Creating metrics dataframe
2024-03-20 15:00:26,498:INFO:Initializing Light Gradient Boosting Machine
2024-03-20 15:00:26,498:INFO:Total runtime is 0.6509530822436015 minutes
2024-03-20 15:00:26,498:INFO:SubProcess create_model() called ==================================
2024-03-20 15:00:26,498:INFO:Initializing create_model()
2024-03-20 15:00:26,498:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239081B5750>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023925820C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 15:00:26,498:INFO:Checking exceptions
2024-03-20 15:00:26,498:INFO:Importing libraries
2024-03-20 15:00:26,498:INFO:Copying training dataset
2024-03-20 15:00:26,526:INFO:Defining folds
2024-03-20 15:00:26,526:INFO:Declaring metric variables
2024-03-20 15:00:26,529:INFO:Importing untrained model
2024-03-20 15:00:26,532:INFO:Light Gradient Boosting Machine Imported successfully
2024-03-20 15:00:26,536:INFO:Starting cross validation
2024-03-20 15:00:26,536:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 15:00:28,229:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:28,243:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:28,290:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:28,343:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:28,354:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:28,354:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:28,420:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:28,436:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:28,504:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:28,504:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:28,535:INFO:Calculating mean and std
2024-03-20 15:00:28,535:INFO:Creating metrics dataframe
2024-03-20 15:00:28,535:INFO:Uploading results into container
2024-03-20 15:00:28,540:INFO:Uploading model into container now
2024-03-20 15:00:28,540:INFO:_master_model_container: 14
2024-03-20 15:00:28,541:INFO:_display_container: 2
2024-03-20 15:00:28,541:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=979, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-03-20 15:00:28,541:INFO:create_model() successfully completed......................................
2024-03-20 15:00:28,866:INFO:SubProcess create_model() end ==================================
2024-03-20 15:00:28,866:INFO:Creating metrics dataframe
2024-03-20 15:00:28,874:INFO:Initializing Dummy Classifier
2024-03-20 15:00:28,874:INFO:Total runtime is 0.6905622323354086 minutes
2024-03-20 15:00:28,874:INFO:SubProcess create_model() called ==================================
2024-03-20 15:00:28,874:INFO:Initializing create_model()
2024-03-20 15:00:28,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239081B5750>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023925820C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 15:00:28,874:INFO:Checking exceptions
2024-03-20 15:00:28,874:INFO:Importing libraries
2024-03-20 15:00:28,874:INFO:Copying training dataset
2024-03-20 15:00:28,903:INFO:Defining folds
2024-03-20 15:00:28,903:INFO:Declaring metric variables
2024-03-20 15:00:28,906:INFO:Importing untrained model
2024-03-20 15:00:28,908:INFO:Dummy Classifier Imported successfully
2024-03-20 15:00:28,914:INFO:Starting cross validation
2024-03-20 15:00:28,915:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-03-20 15:00:29,117:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:29,123:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:29,124:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:29,124:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:29,150:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:29,151:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:29,153:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:29,158:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:29,158:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:29,158:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:29,166:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:29,166:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:29,178:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:29,178:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:29,185:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:29,185:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:29,199:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:29,199:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method='predict_proba', average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
                ~^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\admcn\anaconda3\Lib\site-packages\pandas\core\indexes\base.py", line 6176, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['device'], dtype='object')] are in the [columns]"

  warnings.warn(

2024-03-20 15:00:29,205:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:29,208:WARNING:C:\Users\admcn\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-03-20 15:00:29,213:INFO:Calculating mean and std
2024-03-20 15:00:29,213:INFO:Creating metrics dataframe
2024-03-20 15:00:29,220:INFO:Uploading results into container
2024-03-20 15:00:29,221:INFO:Uploading model into container now
2024-03-20 15:00:29,221:INFO:_master_model_container: 15
2024-03-20 15:00:29,221:INFO:_display_container: 2
2024-03-20 15:00:29,221:INFO:DummyClassifier(constant=None, random_state=979, strategy='prior')
2024-03-20 15:00:29,221:INFO:create_model() successfully completed......................................
2024-03-20 15:00:29,520:INFO:SubProcess create_model() end ==================================
2024-03-20 15:00:29,520:INFO:Creating metrics dataframe
2024-03-20 15:00:29,539:INFO:Initializing create_model()
2024-03-20 15:00:29,539:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000239081B5750>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=979, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-03-20 15:00:29,539:INFO:Checking exceptions
2024-03-20 15:00:29,541:INFO:Importing libraries
2024-03-20 15:00:29,541:INFO:Copying training dataset
2024-03-20 15:00:29,564:INFO:Defining folds
2024-03-20 15:00:29,564:INFO:Declaring metric variables
2024-03-20 15:00:29,564:INFO:Importing untrained model
2024-03-20 15:00:29,564:INFO:Declaring custom model
2024-03-20 15:00:29,564:INFO:Logistic Regression Imported successfully
2024-03-20 15:00:29,567:INFO:Cross validation set to False
2024-03-20 15:00:29,567:INFO:Fitting Model
2024-03-20 15:00:29,824:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=979, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-03-20 15:00:29,824:INFO:create_model() successfully completed......................................
2024-03-20 15:00:30,133:INFO:_master_model_container: 15
2024-03-20 15:00:30,133:INFO:_display_container: 2
2024-03-20 15:00:30,134:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=979, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-03-20 15:00:30,134:INFO:compare_models() successfully completed......................................
2024-03-21 01:50:49,517:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-21 01:50:49,517:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-21 01:50:49,517:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-03-21 01:50:49,517:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
